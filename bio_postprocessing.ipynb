{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b72888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from oml.datasets.base import DatasetWithLabels, DatasetQueryGallery\n",
    "from oml.inference.flat import inference_on_dataframe\n",
    "from oml.metrics.embeddings import EmbeddingMetrics\n",
    "from oml.miners.pairs import PairsMiner\n",
    "from oml.models.siamese import ConcatSiamese\n",
    "from oml.models.vit.vit import ViTExtractor\n",
    "from oml.retrieval.postprocessors.pairwise import PairwiseImagesPostprocessor\n",
    "from oml.samplers.category_balance import CategoryBalanceSampler\n",
    "from oml.transforms.images.torchvision.transforms import get_normalisation_resize_torch\n",
    "from oml.utils.download_mock_dataset import download_mock_dataset\n",
    "from oml.interfaces.datasets import IDatasetWithLabels\n",
    "from oml import const\n",
    "\n",
    "from source import BioDatasetWithLabels, SimpleSiamese, SimpleExtractor, PairsSamplerTwoModalities\n",
    "\n",
    "\"\"\"\n",
    "we have 4 hid\n",
    "\n",
    "data sctructure:\n",
    "\n",
    "hid u1 u2   | v1  v2  v3 \n",
    "0   5.4 3.2 | 5.3 5.4 9.0\n",
    "0   5.4 6.2 | 2.3 5.3 9.0\n",
    "1   5.4 3.2 | 5.3 9.4 9.0\n",
    "1   5.2 3.1 | 5.2 5.1 9.0\n",
    "\n",
    "\n",
    "2   5.4 3.2 | 5.3 5.4 9.0\n",
    "2   5.4 6.2 | 2.3 5.3 9.0\n",
    "3   5.4 3.2 | 5.3 9.4 9.0\n",
    "3   5.2 3.1 | 5.2 5.1 9.0\n",
    "\n",
    "\n",
    "e1\n",
    "e2\n",
    "siamese(e1(x1),e2(x2))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# I assume that descriptors of both types will have the same size after PCA\n",
    "feat_dim_after_pca = 64\n",
    "\n",
    "labels =        [0, 0, 1, 1, 2, 2, 3, 3]\n",
    "categories =    [0, 0, 0, 0, 1, 1, 1, 1]  # this is a hospital id\n",
    "is_first_type = [1, 0, 1, 0, 1, 0, 1, 0]\n",
    "descriptors =   torch.randn((len(labels), feat_dim_after_pca))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36feb3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tensors': tensor([ 0.8439,  1.1075, -1.8287, -1.8799,  1.0038, -0.4417,  0.1399, -1.5350,\n",
       "          0.8361,  0.6795, -1.1870,  0.9015, -0.5298, -0.7333,  0.8621,  0.5923,\n",
       "         -1.2551,  0.5639,  3.1262,  0.9393, -0.3574, -0.8543, -1.0328, -0.4436,\n",
       "         -2.1585, -0.8695, -1.7186,  0.5806,  1.6303, -1.8406, -1.5857, -0.3112,\n",
       "         -0.3475, -0.3353,  0.1391, -1.8080,  0.5724,  0.2229, -0.2842,  0.4157,\n",
       "          0.2724, -1.0671,  0.4637,  0.4134,  0.3679,  1.1582, -1.2600, -0.0702,\n",
       "          1.0421,  1.6099, -0.0864,  1.1118, -0.8526, -0.9129,  1.3778, -0.5983,\n",
       "          1.0534,  0.6310,  0.4721,  0.3414,  0.2091, -0.0742, -0.2267, -0.1156]),\n",
       " 'labels': 0,\n",
       " 'categories': 0,\n",
       " 'is_first_type': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f9b4d17",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'in_dim' and 'out_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# these extractors were trained on a first stage (for example, as a part of CLIP)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m extractor1 \u001b[38;5;241m=\u001b[39m SimpleExtractor()\n\u001b[1;32m      3\u001b[0m extractor2 \u001b[38;5;241m=\u001b[39m SimpleExtractor()\n\u001b[1;32m      5\u001b[0m embeddings_train, embeddings_val, df_train, df_val \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m      6\u001b[0m     inference_on_dataframe(dataset_root, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, extractor\u001b[38;5;241m=\u001b[39mextractor, transforms_extraction\u001b[38;5;241m=\u001b[39mtransform)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'in_dim' and 'out_dim'"
     ]
    }
   ],
   "source": [
    "# these extractors were trained on a first stage (for example, as a part of CLIP)\n",
    "extractor1 = SimpleExtractor(in_dim=feat_dim_after_pca, out_dim=18)\n",
    "extractor2 = SimpleExtractor(in_dim=feat_dim_after_pca, out_dim=24)\n",
    "\n",
    "embeddings_train, embeddings_val, df_train, df_val = \\\n",
    "    inference_on_dataframe(dataset_root, \"df.csv\", extractor=extractor, transforms_extraction=transform)\n",
    "\n",
    "siamese = SimpleSiamese(extractor1=extractor1, extractor2=extractor2)\n",
    "optimizer = torch.optim.SGD(siamese.parameters(), lr=1e-6)\n",
    "miner = PairsSamplerTwoModalities()\n",
    "criterion = BCEWithLogitsLoss()\n",
    "\n",
    "train_dataset = BioDatasetWithLabels(labels, categories, is_first_type, descriptors)\n",
    "batch_sampler = CategoryBalanceSampler(train_dataset.get_labels(), n_labels=10, n_instances=2, n_categories=1)\n",
    "train_loader = DataLoader(train_dataset, batch_sampler=batch_sampler)\n",
    "\n",
    "for batch in train_loader:\n",
    "    features_a = batch[const.INPUT_TENSORS_KEY][batch[\"is_first_type\"]]\n",
    "    features_b = batch[const.INPUT_TENSORS_KEY][~batch[\"is_first_type\"]]\n",
    "    labels_a = batch[const.LABELS_KEY][batch[\"is_first_type\"]]\n",
    "    labels_b = batch[const.LABELS_KEY][~batch[\"is_first_type\"]]\n",
    "    \n",
    "    ids1, ids2, is_negative_pair = miner.sample(features_a, features_b, labels_a, labels_b)\n",
    "    probs = siamese(x1=batch[\"input_tensors\"][ids1], x2=batch[\"input_tensors\"][ids2])\n",
    "    loss = criterion(probs, is_negative_pair.float())\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ee013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese re-ranks top-n retrieval outputs of the original model performing inference on pairs (query, output_i)\n",
    "val_dataset = DatasetQueryGallery(df=df_val, extra_data={\"embeddings\": embeddings_val}, transform=transform)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "postprocessor = PairwiseImagesPostprocessor(top_n=3, pairwise_model=siamese, transforms=transform)\n",
    "calculator = EmbeddingMetrics(postprocessor=postprocessor)\n",
    "calculator.setup(num_samples=len(val_dataset))\n",
    "\n",
    "for batch in valid_loader:\n",
    "    calculator.update_data(data_dict=batch)\n",
    "\n",
    "pprint(calculator.compute_metrics())  # Pairwise inference happens here"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Отсутствует",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
